{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b917777",
   "metadata": {},
   "source": [
    "# BAST Multitask Training Notebook\n",
    "\n",
    "This notebook recreates the training loop from `train_multitask.py` with all configuration set directly here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from network.BAST import BAST_Variant, AngularLossWithCartesianCoordinate, MixWithCartesianCoordinate , MSELossWithPolarCoordinate, AzElLossDegrees\n",
    "from data_loading import SpectrogramDataset\n",
    "import argparse  # Not used but keeping for compatibility\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Set all parameters directly here\n",
    "\n",
    "# Dataset configuration\n",
    "CSV_PATH = 'tensor_metadata.csv'  # Replace with your CSV file path\n",
    "\n",
    "# Model architecture parameters\n",
    "SPECTROGRAM_SIZE = [64, 18]  # [frequency_bins, time_frames] - cropped to 100ms\n",
    "PATCH_SIZE = 16\n",
    "PATCH_OVERLAP = 10\n",
    "NUM_OUTPUT = 2  # Output dimension for localization: [azimuth_deg, elevation_deg]\n",
    "EMBEDDING_DIM = 1024\n",
    "TRANSFORMER_DEPTH = 3\n",
    "TRANSFORMER_HEADS = 16\n",
    "TRANSFORMER_MLP_DIM = 1024\n",
    "TRANSFORMER_DIM_HEAD = 64\n",
    "INPUT_CHANNEL = 1  # Single channel per ear\n",
    "DROPOUT = 0.2\n",
    "EMB_DROPOUT = 0.2\n",
    "TRANSFORMER_POOL = 'conv'\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 1500\n",
    "LEARNING_RATE = 0.0001\n",
    "TEST_SPLIT = 0.1  # Test split ratio (10% of total dataset)\n",
    "VAL_SPLIT = 0.2   # Validation split ratio (20% of remaining 90% after test split)\n",
    "SEED = 42\n",
    "\n",
    "# Loss weights\n",
    "LOC_WEIGHT = 1.0      # Azimuth-elevation loss (AzElLossDegrees)\n",
    "CLS_WEIGHT = 1.0      # Classification loss weight\n",
    "OBJ_WEIGHT = 1.0      # Objectness loss weight\n",
    "\n",
    "# Model configuration\n",
    "BACKBONE = 'vanilla'  # Transformer variant: 'vanilla'\n",
    "BINAURAL_INTEGRATION = 'SUB'  # 'SUB', 'ADD', 'CONCAT'\n",
    "SHARE_WEIGHTS = False  # Share weights between left/right branches\n",
    "MAX_SOURCES = 4        # number of detection slots\n",
    "LOSS_TYPE = 'AZEL'     # Localization loss: 'AZEL' (degrees)\n",
    "\n",
    "# GPU configuration\n",
    "GPU_LIST = [0] if torch.cuda.is_available() else []  # Use GPU 0 if available\n",
    "\n",
    "# Directory configuration\n",
    "MODEL_SAVE_DIR = './output/models/'\n",
    "MODEL_NAME = 'BAST'\n",
    "\n",
    "# DataLoader configuration\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get localization criterion\n",
    "def get_localization_criterion(name: str):\n",
    "    if name == 'AZEL':\n",
    "        return AzElLossDegrees()\n",
    "    if name == 'MSE':\n",
    "        return nn.MSELoss()\n",
    "    if name == 'AD':\n",
    "        return AngularLossWithCartesianCoordinate()\n",
    "    if name == 'MIX':\n",
    "        return MixWithCartesianCoordinate()\n",
    "    if name == \"MSE_POLAR\":\n",
    "        return MSELossWithPolarCoordinate()\n",
    "    raise ValueError('Unknown localization loss')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c51a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-25 13:05:03.770189] Loading dataset from tensor_metadata.csv ...\n",
      "[2025-08-25 13:05:03.774093] Samples: 3190 | Classes: 3\n",
      "Train set: 2297 samples\n",
      "Validation set: 574 samples\n",
      "Test set: 319 samples\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "print(f\"[{datetime.now()}] Loading dataset from {CSV_PATH} ...\")\n",
    "dataset = SpectrogramDataset(CSV_PATH)\n",
    "num_classes = len(dataset.class_to_index)\n",
    "print(f\"[{datetime.now()}] Samples: {len(dataset)} | Classes: {num_classes}\")\n",
    "\n",
    "# Create train/test/validation split\n",
    "test_size = int(len(dataset) * TEST_SPLIT)\n",
    "remaining_size = len(dataset) - test_size\n",
    "\n",
    "# First split off test set\n",
    "remaining_ds, test_ds = random_split(dataset, [remaining_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Then split remaining into train and validation\n",
    "val_size = int(remaining_size * VAL_SPLIT)\n",
    "train_size = remaining_size - val_size\n",
    "train_ds, val_ds = random_split(remaining_ds, [train_size, val_size], generator=torch.Generator().manual_seed(SEED+1))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train set: {len(train_ds)} samples\")\n",
    "print(f\"Validation set: {len(val_ds)} samples\")\n",
    "print(f\"Test set: {len(test_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3a2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-25 13:05:03.778356] Building model ...\n",
      "Model built successfully. Using device: cuda\n",
      "Model parameters: 57002031\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "print(f\"[{datetime.now()}] Building model ...\")\n",
    "\n",
    "net = BAST_Variant(\n",
    "    image_size=SPECTROGRAM_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    patch_overlap=PATCH_OVERLAP,\n",
    "    num_coordinates_output=NUM_OUTPUT,\n",
    "    dim=EMBEDDING_DIM,\n",
    "    depth=TRANSFORMER_DEPTH,\n",
    "    heads=TRANSFORMER_HEADS,\n",
    "    mlp_dim=TRANSFORMER_MLP_DIM,\n",
    "    pool=TRANSFORMER_POOL,\n",
    "    channels=INPUT_CHANNEL,\n",
    "    dim_head=TRANSFORMER_DIM_HEAD,\n",
    "    dropout=DROPOUT,\n",
    "    emb_dropout=EMB_DROPOUT,\n",
    "    binaural_integration=BINAURAL_INTEGRATION,\n",
    "    share_params=SHARE_WEIGHTS,\n",
    "    transformer_variant=BACKBONE,\n",
    "    max_sources=MAX_SOURCES,\n",
    "    classify_sound=True,\n",
    "    num_classes_cls=num_classes,\n",
    ")\n",
    "\n",
    "# Setup device and move model to device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "if use_cuda and GPU_LIST:\n",
    "    net = nn.DataParallel(net, device_ids=GPU_LIST).to(device)\n",
    "else:\n",
    "    net = net.to(device)\n",
    "\n",
    "print(f\"Model built successfully. Using device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in net.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd512e7d",
   "metadata": {},
   "source": [
    "We now use a detection-style head that outputs per-source slots: (loc_out [B,K,2], obj_logit [B,K], cls_logit [B,K,C]). Losses are computed after matching GT sources to slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved as: BAST_SUB_MIX_DET_NSP_vanilla\n",
      "Training for 60 epochs with batch size 1500\n",
      "Learning rate: 0.0001\n",
      "Loss weights - Loc: 1.0, Elev: 0.1, Cls: 1.0, Obj: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer and loss functions\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=0.0)\n",
    "criterion_loc = get_localization_criterion(LOSS_TYPE)   # AzElLossDegrees by default\n",
    "criterion_obj = nn.BCEWithLogitsLoss(reduction='none')  # per-slot objectness\n",
    "criterion_cls = nn.BCEWithLogitsLoss(reduction='none')  # multi-label per class per slot\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = f\"{MODEL_NAME}_{BINAURAL_INTEGRATION}_{LOSS_TYPE}_DET_{'SP' if SHARE_WEIGHTS else 'NSP'}_{BACKBONE}\"\n",
    "\n",
    "print(f\"Model will be saved as: {model_save_name}\")\n",
    "print(f\"Training for {EPOCHS} epochs with batch size {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Loss weights - Loc: {LOC_WEIGHT}, Cls: {CLS_WEIGHT}, Obj: {OBJ_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-25 13:05:04.195693] Start training ...\n",
      "[2025-08-25 13:05:10.273299] Epoch 001/60 | train 286.6908 | val 271.6232\n",
      "  -> Saved best model with validation loss: 271.6232\n",
      "[2025-08-25 13:05:16.323986] Epoch 002/60 | train 284.5599 | val 270.3448\n",
      "  -> Saved best model with validation loss: 270.3448\n",
      "[2025-08-25 13:05:22.542857] Epoch 003/60 | train 282.9873 | val 269.3232\n",
      "  -> Saved best model with validation loss: 269.3232\n",
      "[2025-08-25 13:05:28.752928] Epoch 004/60 | train 280.9571 | val 268.5024\n",
      "  -> Saved best model with validation loss: 268.5024\n",
      "[2025-08-25 13:05:35.083589] Epoch 005/60 | train 279.6840 | val 268.7466\n",
      "[2025-08-25 13:05:41.175763] Epoch 006/60 | train 277.9407 | val 267.4231\n",
      "  -> Saved best model with validation loss: 267.4231\n",
      "[2025-08-25 13:05:47.411531] Epoch 007/60 | train 276.6226 | val 266.0373\n",
      "  -> Saved best model with validation loss: 266.0373\n",
      "[2025-08-25 13:05:53.717310] Epoch 008/60 | train 275.2166 | val 264.9369\n",
      "  -> Saved best model with validation loss: 264.9369\n",
      "[2025-08-25 13:05:59.955080] Epoch 009/60 | train 273.9956 | val 263.8871\n",
      "  -> Saved best model with validation loss: 263.8871\n",
      "[2025-08-25 13:06:06.190304] Epoch 010/60 | train 272.4687 | val 261.9897\n",
      "  -> Saved best model with validation loss: 261.9897\n",
      "[2025-08-25 13:06:12.511584] Epoch 011/60 | train 270.8397 | val 261.7547\n",
      "  -> Saved best model with validation loss: 261.7547\n",
      "[2025-08-25 13:06:18.975094] Epoch 012/60 | train 269.1855 | val 260.3798\n",
      "  -> Saved best model with validation loss: 260.3798\n",
      "[2025-08-25 13:06:25.198265] Epoch 013/60 | train 267.1528 | val 260.8171\n",
      "[2025-08-25 13:06:31.239422] Epoch 014/60 | train 266.5315 | val 258.6099\n",
      "  -> Saved best model with validation loss: 258.6099\n",
      "[2025-08-25 13:06:37.515536] Epoch 015/60 | train 263.9491 | val 256.7348\n",
      "  -> Saved best model with validation loss: 256.7348\n",
      "[2025-08-25 13:06:43.812033] Epoch 016/60 | train 262.1410 | val 256.0047\n",
      "  -> Saved best model with validation loss: 256.0047\n",
      "[2025-08-25 13:06:50.538323] Epoch 017/60 | train 260.5510 | val 253.9172\n",
      "  -> Saved best model with validation loss: 253.9172\n",
      "[2025-08-25 13:06:57.354632] Epoch 018/60 | train 258.4136 | val 252.9426\n",
      "  -> Saved best model with validation loss: 252.9426\n",
      "[2025-08-25 13:07:03.997551] Epoch 019/60 | train 256.7315 | val 250.2630\n",
      "  -> Saved best model with validation loss: 250.2630\n",
      "[2025-08-25 13:07:10.700069] Epoch 020/60 | train 254.8194 | val 248.9268\n",
      "  -> Saved best model with validation loss: 248.9268\n",
      "[2025-08-25 13:07:17.423974] Epoch 021/60 | train 252.3676 | val 245.6547\n",
      "  -> Saved best model with validation loss: 245.6547\n",
      "[2025-08-25 13:07:24.049422] Epoch 022/60 | train 248.6607 | val 243.2953\n",
      "  -> Saved best model with validation loss: 243.2953\n",
      "[2025-08-25 13:07:30.782647] Epoch 023/60 | train 245.9034 | val 239.8976\n",
      "  -> Saved best model with validation loss: 239.8976\n",
      "[2025-08-25 13:07:37.604459] Epoch 024/60 | train 243.0581 | val 238.0786\n",
      "  -> Saved best model with validation loss: 238.0786\n",
      "[2025-08-25 13:07:44.262588] Epoch 025/60 | train 238.9118 | val 235.5195\n",
      "  -> Saved best model with validation loss: 235.5195\n",
      "[2025-08-25 13:07:51.110773] Epoch 026/60 | train 235.7129 | val 231.4183\n",
      "  -> Saved best model with validation loss: 231.4183\n",
      "[2025-08-25 13:07:57.799814] Epoch 027/60 | train 231.2247 | val 224.2362\n",
      "  -> Saved best model with validation loss: 224.2362\n",
      "[2025-08-25 13:08:04.422683] Epoch 028/60 | train 227.0429 | val 226.9702\n",
      "[2025-08-25 13:08:10.696496] Epoch 029/60 | train 224.9961 | val 218.0977\n",
      "  -> Saved best model with validation loss: 218.0977\n",
      "[2025-08-25 13:08:17.554157] Epoch 030/60 | train 219.5488 | val 218.0607\n",
      "  -> Saved best model with validation loss: 218.0607\n",
      "[2025-08-25 13:08:24.171329] Epoch 031/60 | train 216.9300 | val 211.6417\n",
      "  -> Saved best model with validation loss: 211.6417\n",
      "[2025-08-25 13:08:30.872145] Epoch 032/60 | train 210.0124 | val 203.6947\n",
      "  -> Saved best model with validation loss: 203.6947\n",
      "[2025-08-25 13:08:37.498536] Epoch 033/60 | train 206.9223 | val 204.1253\n",
      "[2025-08-25 13:08:43.637126] Epoch 034/60 | train 206.0870 | val 199.9770\n",
      "  -> Saved best model with validation loss: 199.9770\n",
      "[2025-08-25 13:08:50.350829] Epoch 035/60 | train 201.9980 | val 200.9345\n",
      "[2025-08-25 13:08:56.772672] Epoch 036/60 | train 199.5296 | val 196.1957\n",
      "  -> Saved best model with validation loss: 196.1957\n",
      "[2025-08-25 13:09:03.402105] Epoch 037/60 | train 196.6170 | val 191.3390\n",
      "  -> Saved best model with validation loss: 191.3390\n",
      "[2025-08-25 13:09:10.075942] Epoch 038/60 | train 192.1743 | val 190.4369\n",
      "  -> Saved best model with validation loss: 190.4369\n",
      "[2025-08-25 13:09:16.920372] Epoch 039/60 | train 188.9201 | val 184.4467\n",
      "  -> Saved best model with validation loss: 184.4467\n",
      "[2025-08-25 13:09:23.551244] Epoch 040/60 | train 186.0221 | val 180.3917\n",
      "  -> Saved best model with validation loss: 180.3917\n",
      "[2025-08-25 13:09:30.173275] Epoch 041/60 | train 183.2338 | val 177.6515\n",
      "  -> Saved best model with validation loss: 177.6515\n",
      "[2025-08-25 13:09:37.049975] Epoch 042/60 | train 180.0568 | val 176.7369\n",
      "  -> Saved best model with validation loss: 176.7369\n",
      "[2025-08-25 13:09:43.728379] Epoch 043/60 | train 178.2991 | val 174.1727\n",
      "  -> Saved best model with validation loss: 174.1727\n",
      "[2025-08-25 13:09:50.394821] Epoch 044/60 | train 175.3961 | val 169.9934\n",
      "  -> Saved best model with validation loss: 169.9934\n",
      "[2025-08-25 13:09:57.265472] Epoch 045/60 | train 172.9685 | val 169.0375\n",
      "  -> Saved best model with validation loss: 169.0375\n",
      "[2025-08-25 13:10:03.842848] Epoch 046/60 | train 171.4115 | val 167.6951\n",
      "  -> Saved best model with validation loss: 167.6951\n",
      "[2025-08-25 13:10:10.490583] Epoch 047/60 | train 169.1368 | val 166.4525\n",
      "  -> Saved best model with validation loss: 166.4525\n",
      "[2025-08-25 13:10:17.411540] Epoch 048/60 | train 167.2209 | val 165.2226\n",
      "  -> Saved best model with validation loss: 165.2226\n",
      "[2025-08-25 13:10:24.040625] Epoch 049/60 | train 165.6611 | val 163.4184\n",
      "  -> Saved best model with validation loss: 163.4184\n",
      "[2025-08-25 13:10:30.671391] Epoch 050/60 | train 163.6401 | val 158.6788\n",
      "  -> Saved best model with validation loss: 158.6788\n",
      "[2025-08-25 13:10:37.516133] Epoch 051/60 | train 162.5407 | val 158.1115\n",
      "  -> Saved best model with validation loss: 158.1115\n",
      "[2025-08-25 13:10:44.153547] Epoch 052/60 | train 159.4707 | val 159.2654\n",
      "[2025-08-25 13:10:50.409283] Epoch 053/60 | train 158.6664 | val 154.8786\n",
      "  -> Saved best model with validation loss: 154.8786\n",
      "[2025-08-25 13:10:57.272278] Epoch 054/60 | train 157.8281 | val 153.5468\n",
      "  -> Saved best model with validation loss: 153.5468\n",
      "[2025-08-25 13:11:03.967353] Epoch 055/60 | train 155.9622 | val 154.3795\n",
      "[2025-08-25 13:11:10.185145] Epoch 056/60 | train 153.7907 | val 153.5926\n",
      "[2025-08-25 13:11:16.591080] Epoch 057/60 | train 151.8927 | val 152.5682\n",
      "  -> Saved best model with validation loss: 152.5682\n",
      "[2025-08-25 13:11:23.307780] Epoch 058/60 | train 149.8189 | val 151.8194\n",
      "  -> Saved best model with validation loss: 151.8194\n",
      "[2025-08-25 13:11:30.012624] Epoch 059/60 | train 149.6503 | val 149.5871\n",
      "  -> Saved best model with validation loss: 149.5871\n",
      "[2025-08-25 13:11:36.879413] Epoch 060/60 | train 146.4235 | val 146.3717\n",
      "  -> Saved best model with validation loss: 146.3717\n",
      "[2025-08-25 13:11:37.918403] Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Utilities for greedy matching (per sample)\n",
    "def greedy_match_azimuth(pred_az_deg, gt_az_deg):\n",
    "    # pred_az_deg: [K], gt_az_deg: [N]\n",
    "    K = pred_az_deg.size(0)\n",
    "    N = gt_az_deg.size(0)\n",
    "    if N == 0:\n",
    "        return [], torch.empty((0,), dtype=torch.long, device=pred_az_deg.device)\n",
    "    # circular distance in degrees via radians wrap\n",
    "    p = pred_az_deg.unsqueeze(1) * (torch.pi / 180.0)  # [K,1]\n",
    "    g = gt_az_deg.unsqueeze(0) * (torch.pi / 180.0)    # [1,N]\n",
    "    # angle difference wrapped: acos(cos(delta)) or abs(atan2(sin,cos))\n",
    "    delta = torch.atan2(torch.sin(p - g), torch.cos(p - g)).abs()  # [K,N] in radians\n",
    "    d = delta  # already non-negative\n",
    "    matched_pred_idx = []\n",
    "    matched_gt_idx = []\n",
    "    d_clone = d.clone()\n",
    "    while len(matched_pred_idx) < min(K, N):\n",
    "        idx = torch.argmin(d_clone)\n",
    "        pi = (idx // N).item()\n",
    "        gi = (idx % N).item()\n",
    "        matched_pred_idx.append(pi)\n",
    "        matched_gt_idx.append(gi)\n",
    "        d_clone[pi, :] = float('inf')\n",
    "        d_clone[:, gi] = float('inf')\n",
    "    return torch.tensor(matched_pred_idx, device=pred_az_deg.device), torch.tensor(matched_gt_idx, device=pred_az_deg.device)\n",
    "\n",
    "# Training loop\n",
    "print(f\"[{datetime.now()}] Start training ...\")\n",
    "\n",
    "best_val = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    net.train()\n",
    "    running = 0.0\n",
    "    n_train = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        specs, loc_az_el, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_az_el = loc_az_el.to(device, non_blocking=True)    # [B, 2] = [az_deg, el_deg]\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)  # [B]\n",
    "        az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "        # Forward\n",
    "        loc_out, obj_logit, cls_logit = net(specs)\n",
    "        # Shapes: loc_out [B,K,2] (az_deg, el_deg), obj_logit [B,K], cls_logit [B,K,C]\n",
    "\n",
    "        B = specs.size(0)\n",
    "        K = obj_logit.size(1)\n",
    "        C = cls_logit.size(2)\n",
    "\n",
    "        total_loss = torch.tensor(0., device=device)\n",
    "        for b in range(B):\n",
    "            pred_az_el_b = loc_out[b]              # [K,2]\n",
    "            pred_az_b = pred_az_el_b[:, 0]        # [K]\n",
    "            obj_b = obj_logit[b]                  # [K]\n",
    "            cls_b = cls_logit[b]                  # [K,C]\n",
    "\n",
    "            gt_az_el_b = loc_az_el[b].unsqueeze(0)  # [1,2]\n",
    "            gt_az_b = gt_az_el_b[:, 0]              # [1]\n",
    "            gt_cls_multi_hot = torch.zeros(C, device=device)\n",
    "            gt_cls_multi_hot[cls_idx[b]] = 1.0\n",
    "\n",
    "            # Greedy matching on circular azimuth\n",
    "            pred_idx, gt_idx = greedy_match_azimuth(pred_az_b, gt_az_b)\n",
    "\n",
    "            # Objectness targets\n",
    "            obj_target_b = torch.zeros_like(obj_b)\n",
    "            obj_target_b[pred_idx] = 1.0\n",
    "            loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "\n",
    "            # Localization + class on matched slots only\n",
    "            if pred_idx.numel() > 0:\n",
    "                matched_pred_az_el = pred_az_el_b[pred_idx]       # [M,2]\n",
    "                matched_gt_az_el = gt_az_el_b[gt_idx]             # [M,2]\n",
    "                loss_loc_b = criterion_loc(matched_pred_az_el, matched_gt_az_el)\n",
    "\n",
    "                matched_cls = cls_b[pred_idx]\n",
    "                gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "            else:\n",
    "                loss_loc_b = torch.tensor(0., device=device)\n",
    "                loss_cls_b = torch.tensor(0., device=device)\n",
    "\n",
    "            total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "\n",
    "        loss = total_loss / max(1, B)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bsz = specs.size(0)\n",
    "        running += loss.item() * bsz\n",
    "        n_train += bsz\n",
    "\n",
    "    avg_tr = running / max(1, n_train)\n",
    "    train_losses.append(avg_tr)\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()\n",
    "    running_val = 0.0\n",
    "    n_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            specs, loc_az_el, cls_idx, az_el_deg = batch\n",
    "            specs = specs.to(device, non_blocking=True)\n",
    "            loc_az_el = loc_az_el.to(device, non_blocking=True)\n",
    "            cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "            az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "            loc_out, obj_logit, cls_logit = net(specs)\n",
    "            B = specs.size(0)\n",
    "            total_loss = torch.tensor(0., device=device)\n",
    "            for b in range(B):\n",
    "                pred_az_el_b = loc_out[b]\n",
    "                pred_az_b = pred_az_el_b[:, 0]\n",
    "                obj_b = obj_logit[b]\n",
    "                cls_b = cls_logit[b]\n",
    "                gt_az_el_b = loc_az_el[b].unsqueeze(0)\n",
    "                gt_az_b = gt_az_el_b[:, 0]\n",
    "                gt_cls_multi_hot = torch.zeros(cls_b.size(1), device=device)\n",
    "                gt_cls_multi_hot[cls_idx[b]] = 1.0\n",
    "                pred_idx, gt_idx = greedy_match_azimuth(pred_az_b, gt_az_b)\n",
    "                obj_target_b = torch.zeros_like(obj_b); obj_target_b[pred_idx] = 1.0\n",
    "                loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "                if pred_idx.numel() > 0:\n",
    "                    matched_pred_az_el = pred_az_el_b[pred_idx]\n",
    "                    matched_gt_az_el = gt_az_el_b[gt_idx]\n",
    "                    loss_loc_b = criterion_loc(matched_pred_az_el, matched_gt_az_el)\n",
    "                    matched_cls = cls_b[pred_idx]\n",
    "                    gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                    loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "                else:\n",
    "                    loss_loc_b = torch.tensor(0., device=device)\n",
    "                    loss_cls_b = torch.tensor(0., device=device)\n",
    "                total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "            loss = total_loss / max(1, B)\n",
    "            bsz = specs.size(0)\n",
    "            running_val += loss.item() * bsz\n",
    "            n_val += bsz\n",
    "\n",
    "    avg_val = running_val / max(1, n_val)\n",
    "    val_losses.append(avg_val)\n",
    "\n",
    "    print(f\"[{datetime.now()}] Epoch {epoch+1:03d}/{EPOCHS} | train {avg_tr:.4f} | val {avg_val:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val < best_val:\n",
    "        best_val = avg_val\n",
    "        state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': state,\n",
    "            'best_loss': best_val,\n",
    "            'log': {'training': train_losses, 'validation': val_losses},\n",
    "            'conf': {\n",
    "                'image_size': SPECTROGRAM_SIZE,\n",
    "                'patch_size': PATCH_SIZE,\n",
    "                'patch_overlap': PATCH_OVERLAP,\n",
    "                'num_coordinates_output': NUM_OUTPUT,\n",
    "                'max_sources': MAX_SOURCES,\n",
    "            }\n",
    "        }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_best.pkl'))\n",
    "        print(f\"  -> Saved best model with validation loss: {best_val:.4f}\")\n",
    "\n",
    "    # Save last model\n",
    "    state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state,\n",
    "        'best_loss': best_val,\n",
    "        'log': {'training': train_losses, 'validation': val_losses},\n",
    "    }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_last.pkl'))\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "# Evaluate on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb215086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint from: ./output/models/BAST_SUB_MIX_DET_NSP_vanilla_best.pkl\n",
      "[2025-08-25 13:11:37.982717] Evaluating on test set...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "X1 and X2 must have the same number of columns. X1: 3 X2: 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m gt_cls_multi_hot = torch.zeros(cls_b.size(\u001b[32m1\u001b[39m), device=device)\n\u001b[32m     40\u001b[39m gt_cls_multi_hot[cls_idx[b]] = \u001b[32m1.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m pred_idx, gt_idx = \u001b[43mgreedy_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_xy_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_xy_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m obj_target_b = torch.zeros_like(obj_b); obj_target_b[pred_idx] = \u001b[32m1.0\u001b[39m\n\u001b[32m     43\u001b[39m loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mgreedy_match\u001b[39m\u001b[34m(pred_xy, gt_xy)\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [], torch.empty((\u001b[32m0\u001b[39m,), dtype=torch.long, device=pred_xy.device)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# pairwise L2 distance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m d = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [K, N]\u001b[39;00m\n\u001b[32m     10\u001b[39m matched_pred_idx = []\n\u001b[32m     11\u001b[39m matched_gt_idx = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/functional.py:1510\u001b[39m, in \u001b[36mcdist\u001b[39m\u001b[34m(x1, x2, p, compute_mode)\u001b[39m\n\u001b[32m   1506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   1507\u001b[39m         cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode\n\u001b[32m   1508\u001b[39m     )\n\u001b[32m   1509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute_mode == \u001b[33m\"\u001b[39m\u001b[33muse_mm_for_euclid_dist_if_necessary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1510\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m compute_mode == \u001b[33m\"\u001b[39m\u001b[33muse_mm_for_euclid_dist\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF.cdist(x1, x2, p, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: X1 and X2 must have the same number of columns. X1: 3 X2: 2"
     ]
    }
   ],
   "source": [
    "# Load best checkpoint\n",
    "best_ckpt_path = os.path.join(MODEL_SAVE_DIR, model_save_name + '_best.pkl')\n",
    "ckpt = torch.load(best_ckpt_path, map_location=device)\n",
    "state = ckpt['state_dict']\n",
    "if isinstance(net, nn.DataParallel):\n",
    "    net.module.load_state_dict(state)\n",
    "else:\n",
    "    net.load_state_dict(state)\n",
    "print(f\"Loaded best checkpoint from: {best_ckpt_path}\")\n",
    "\n",
    "print(f\"[{datetime.now()}] Evaluating on test set...\")\n",
    "net.eval()\n",
    "test_running = 0.0\n",
    "n_test = 0\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "az_errors = []\n",
    "el_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "        az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "        loc_out, obj_logit, cls_logit = net(specs)\n",
    "        B = specs.size(0)\n",
    "\n",
    "        # Compute detection loss as in validation (optional during eval)\n",
    "        total_loss = torch.tensor(0., device=device)\n",
    "        for b in range(B):\n",
    "            pred_xy_b = loc_out[b][..., :2]\n",
    "            obj_b = obj_logit[b]\n",
    "            cls_b = cls_logit[b]\n",
    "            gt_xy_b = loc_xy[b].unsqueeze(0)\n",
    "            gt_cls_multi_hot = torch.zeros(cls_b.size(1), device=device)\n",
    "            gt_cls_multi_hot[cls_idx[b]] = 1.0\n",
    "            pred_idx, gt_idx = greedy_match(pred_xy_b, gt_xy_b)\n",
    "            obj_target_b = torch.zeros_like(obj_b); obj_target_b[pred_idx] = 1.0\n",
    "            loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "            if pred_idx.numel() > 0:\n",
    "                matched_pred_xy = pred_xy_b[pred_idx]\n",
    "                matched_gt_xy = gt_xy_b[gt_idx]\n",
    "                loss_loc_b = criterion_loc(matched_pred_xy, matched_gt_xy)\n",
    "                matched_cls = cls_b[pred_idx]\n",
    "                gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "            else:\n",
    "                loss_loc_b = torch.tensor(0., device=device)\n",
    "                loss_cls_b = torch.tensor(0., device=device)\n",
    "            total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "        loss = total_loss / max(1, B)\n",
    "\n",
    "        # Metrics: select best slot by objectness\n",
    "        obj_prob = torch.sigmoid(obj_logit)  # [B,K]\n",
    "        best_slot = torch.argmax(obj_prob, dim=1)  # [B]\n",
    "        batch_idx = torch.arange(B, device=device)\n",
    "\n",
    "        pred_loc = loc_out[batch_idx, best_slot]           # [B, num_coordinates_output]\n",
    "        pred_cls_logits = cls_logit[batch_idx, best_slot]  # [B, C]\n",
    "        pred_cls = torch.argmax(pred_cls_logits, dim=1)\n",
    "\n",
    "        test_correct += (pred_cls == cls_idx).sum().item()\n",
    "        test_total += B\n",
    "\n",
    "        # Azimuth error from unit vector [x,y]\n",
    "        pred_theta = torch.atan2(pred_loc[:, 1], pred_loc[:, 0])\n",
    "        pred_az_deg = pred_theta * 180.0 / torch.pi\n",
    "        true_az_deg = az_el_deg[:, 0]\n",
    "        az_err = torch.abs(pred_az_deg - true_az_deg)\n",
    "        az_err = torch.min(az_err, 360 - az_err)\n",
    "        az_errors.extend(az_err.detach().cpu().numpy())\n",
    "\n",
    "        # Elevation error (3rd component is elevation in degrees)\n",
    "        if pred_loc.size(1) >= 3:\n",
    "            pred_el_deg = pred_loc[:, 2]\n",
    "            el_err = torch.abs(pred_el_deg - az_el_deg[:, 1])\n",
    "            el_errors.extend(el_err.detach().cpu().numpy())\n",
    "\n",
    "        bsz = specs.size(0)\n",
    "        test_running += loss.item() * bsz\n",
    "        n_test += bsz\n",
    "\n",
    "avg_test = test_running / max(1, n_test)\n",
    "cls_acc = test_correct / max(1, test_total)\n",
    "mean_az_err = float(np.mean(az_errors)) if len(az_errors) else float('nan')\n",
    "mean_el_err = float(np.mean(el_errors)) if len(el_errors) else float('nan')\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "print(f\"Best validation loss: {best_val:.4f}\")\n",
    "print(f\"Test loss: {avg_test:.4f}\")\n",
    "print(f\"Classification accuracy: {cls_acc:.4f}\")\n",
    "print(f\"Average azimuth error: {mean_az_err:.2f}°\")\n",
    "if len(el_errors):\n",
    "    print(f\"Average elevation error: {mean_el_err:.2f}°\")\n",
    "else:\n",
    "    print(\"Average elevation error: n/a (model does not output elevation)\")\n",
    "print(f\"Models saved in: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9abe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (Log Scale)')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d1e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
