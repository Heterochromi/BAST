{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b917777",
   "metadata": {},
   "source": [
    "# BAST Multitask Training Notebook\n",
    "\n",
    "This notebook recreates the training loop from `train_multitask.py` with all configuration set directly here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from network.BAST import BAST_Variant, AngularLossWithCartesianCoordinate, MixWithCartesianCoordinate\n",
    "from data_loading import SpectrogramDataset\n",
    "import argparse  # Not used but keeping for compatibility\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Set all parameters directly here\n",
    "\n",
    "# Dataset configuration\n",
    "CSV_PATH = 'tensor_metadata.csv'  # Replace with your CSV file path\n",
    "\n",
    "# Model architecture parameters\n",
    "SPECTROGRAM_SIZE = [64, 18]  # [frequency_bins, time_frames] - cropped to 100ms\n",
    "PATCH_SIZE = 16\n",
    "PATCH_OVERLAP = 10\n",
    "NUM_OUTPUT = 2  # Output dimension for localization\n",
    "EMBEDDING_DIM = 1024\n",
    "TRANSFORMER_DEPTH = 3\n",
    "TRANSFORMER_HEADS = 16\n",
    "TRANSFORMER_MLP_DIM = 1024\n",
    "TRANSFORMER_DIM_HEAD = 64\n",
    "INPUT_CHANNEL = 1  # Single channel per ear\n",
    "DROPOUT = 0.2\n",
    "EMB_DROPOUT = 0.2\n",
    "TRANSFORMER_POOL = 'conv'\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 1500\n",
    "LEARNING_RATE = 0.0001\n",
    "TEST_SPLIT = 0.1  # Test split ratio (10% of total dataset)\n",
    "VAL_SPLIT = 0.2   # Validation split ratio (20% of remaining 90% after test split)\n",
    "SEED = 42\n",
    "\n",
    "# Loss weights for multitask learning\n",
    "CLS_WEIGHT = 1.0      # Classification loss weight\n",
    "ELEV_WEIGHT = 0.1     # Elevation regression loss weight\n",
    "\n",
    "# Model configuration\n",
    "BACKBONE = 'vanilla'  # Transformer variant: 'vanilla'\n",
    "BINAURAL_INTEGRATION = 'SUB'  # 'SUB', 'ADD', 'CONCAT'\n",
    "SHARE_WEIGHTS = False  # Share weights between left/right branches\n",
    "LOSS_TYPE = 'MIX'     # Localization loss: 'MSE', 'AD', 'MIX'\n",
    "\n",
    "# GPU configuration\n",
    "GPU_LIST = [0] if torch.cuda.is_available() else []  # Use GPU 0 if available\n",
    "\n",
    "# Directory configuration\n",
    "MODEL_SAVE_DIR = './output/models/'\n",
    "MODEL_NAME = 'BAST'\n",
    "\n",
    "# DataLoader configuration\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get localization criterion\n",
    "def get_localization_criterion(name: str):\n",
    "    if name == 'MSE':\n",
    "        return nn.MSELoss()\n",
    "    if name == 'AD':\n",
    "        return AngularLossWithCartesianCoordinate()\n",
    "    if name == 'MIX':\n",
    "        return MixWithCartesianCoordinate()\n",
    "    raise ValueError('Unknown localization loss')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "print(f\"[{datetime.now()}] Loading dataset from {CSV_PATH} ...\")\n",
    "dataset = SpectrogramDataset(CSV_PATH)\n",
    "num_classes = len(dataset.class_to_index)\n",
    "print(f\"[{datetime.now()}] Samples: {len(dataset)} | Classes: {num_classes}\")\n",
    "\n",
    "# Create train/test/validation split\n",
    "test_size = int(len(dataset) * TEST_SPLIT)\n",
    "remaining_size = len(dataset) - test_size\n",
    "\n",
    "# First split off test set\n",
    "remaining_ds, test_ds = random_split(dataset, [remaining_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Then split remaining into train and validation\n",
    "val_size = int(remaining_size * VAL_SPLIT)\n",
    "train_size = remaining_size - val_size\n",
    "train_ds, val_ds = random_split(remaining_ds, [train_size, val_size], generator=torch.Generator().manual_seed(SEED+1))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train set: {len(train_ds)} samples\")\n",
    "print(f\"Validation set: {len(val_ds)} samples\")\n",
    "print(f\"Test set: {len(test_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "print(f\"[{datetime.now()}] Building model ...\")\n",
    "\n",
    "net = BAST_Variant(\n",
    "    image_size=SPECTROGRAM_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    patch_overlap=PATCH_OVERLAP,\n",
    "    num_classes=NUM_OUTPUT,\n",
    "    dim=EMBEDDING_DIM,\n",
    "    depth=TRANSFORMER_DEPTH,\n",
    "    heads=TRANSFORMER_HEADS,\n",
    "    mlp_dim=TRANSFORMER_MLP_DIM,\n",
    "    pool=TRANSFORMER_POOL,\n",
    "    channels=INPUT_CHANNEL,\n",
    "    dim_head=TRANSFORMER_DIM_HEAD,\n",
    "    dropout=DROPOUT,\n",
    "    emb_dropout=EMB_DROPOUT,\n",
    "    binaural_integration=BINAURAL_INTEGRATION,\n",
    "    share_params=SHARE_WEIGHTS,\n",
    "    transformer_variant=BACKBONE,\n",
    "    classify_sound=True,\n",
    "    num_classes_cls=num_classes,\n",
    "    regress_elevation=True,\n",
    ")\n",
    "\n",
    "# Setup device and move model to device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "if use_cuda and GPU_LIST:\n",
    "    net = nn.DataParallel(net, device_ids=GPU_LIST).to(device)\n",
    "else:\n",
    "    net = net.to(device)\n",
    "\n",
    "print(f\"Model built successfully. Using device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in net.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and loss functions\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=0.0)\n",
    "criterion_loc = get_localization_criterion(LOSS_TYPE)\n",
    "\n",
    "if num_classes > 1:\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion_cls = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "criterion_elev = nn.MSELoss()\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = f\"{MODEL_NAME}_{BINAURAL_INTEGRATION}_{LOSS_TYPE}_MT_{'SP' if SHARE_WEIGHTS else 'NSP'}_{BACKBONE}\"\n",
    "\n",
    "print(f\"Model will be saved as: {model_save_name}\")\n",
    "print(f\"Training for {EPOCHS} epochs with batch size {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Loss weights - Classification: {CLS_WEIGHT}, Elevation: {ELEV_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e0e189",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 101258, 101262, 101263) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/queue.py:179\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m n_val = \u001b[32m0\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maz_el_deg\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BAST/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1298\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1297\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1299\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1300\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 101258, 101262, 101263) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(f\"[{datetime.now()}] Start training ...\")\n",
    "\n",
    "best_val = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    net.train()\n",
    "    running = 0.0\n",
    "    n_train = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "        az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = net(specs)\n",
    "        # outputs: (loc_out, cls_out, elev_out)\n",
    "        loc_out = outputs[0]\n",
    "        cls_out = outputs[1]\n",
    "        elev_out = outputs[2]\n",
    "\n",
    "        # Calculate losses\n",
    "        loss_loc = criterion_loc(loc_out, loc_xy)\n",
    "        \n",
    "        if num_classes > 1:\n",
    "            loss_cls = criterion_cls(cls_out, cls_idx)\n",
    "        else:\n",
    "            # BCE expects float targets with shape [B,1]\n",
    "            target_bce = cls_idx.float().unsqueeze(1)\n",
    "            loss_cls = criterion_cls(cls_out, target_bce)\n",
    "        \n",
    "        # elevation is a single scalar in degrees\n",
    "        loss_elev = criterion_elev(elev_out.squeeze(1), az_el_deg[:, 1])\n",
    "\n",
    "        # Combined loss\n",
    "        loss = loss_loc + CLS_WEIGHT * loss_cls + ELEV_WEIGHT * loss_elev\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bsz = specs.size(0)\n",
    "        running += loss.item() * bsz\n",
    "        n_train += bsz\n",
    "\n",
    "    avg_tr = running / max(1, n_train)\n",
    "    train_losses.append(avg_tr)\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()\n",
    "    running_val = 0.0\n",
    "    n_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "            specs = specs.to(device, non_blocking=True)\n",
    "            loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "            cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "            az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = net(specs)\n",
    "            loc_out = outputs[0]\n",
    "            cls_out = outputs[1]\n",
    "            elev_out = outputs[2]\n",
    "\n",
    "            loss_loc = criterion_loc(loc_out, loc_xy)\n",
    "            \n",
    "            if num_classes > 1:\n",
    "                loss_cls = criterion_cls(cls_out, cls_idx)\n",
    "            else:\n",
    "                target_bce = cls_idx.float().unsqueeze(1)\n",
    "                loss_cls = criterion_cls(cls_out, target_bce)\n",
    "            \n",
    "            loss_elev = criterion_elev(elev_out.squeeze(1), az_el_deg[:, 1])\n",
    "\n",
    "            loss = loss_loc + CLS_WEIGHT * loss_cls + ELEV_WEIGHT * loss_elev\n",
    "            bsz = specs.size(0)\n",
    "            running_val += loss.item() * bsz\n",
    "            n_val += bsz\n",
    "\n",
    "    avg_val = running_val / max(1, n_val)\n",
    "    val_losses.append(avg_val)\n",
    "\n",
    "    print(f\"[{datetime.now()}] Epoch {epoch+1:03d}/{EPOCHS} | train {avg_tr:.4f} | val {avg_val:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val < best_val:\n",
    "        best_val = avg_val\n",
    "        state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': state,\n",
    "            'best_loss': best_val,\n",
    "            'log': {'training': train_losses, 'validation': val_losses},\n",
    "            'conf': {\n",
    "                'image_size': SPECTROGRAM_SIZE,\n",
    "                'patch_size': PATCH_SIZE,\n",
    "                'patch_overlap': PATCH_OVERLAP,\n",
    "                'num_classes': NUM_OUTPUT,\n",
    "            }\n",
    "        }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_best.pkl'))\n",
    "        print(f\"  -> Saved best model with validation loss: {best_val:.4f}\")\n",
    "\n",
    "    # Save last model\n",
    "    state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state,\n",
    "        'best_loss': best_val,\n",
    "        'log': {'training': train_losses, 'validation': val_losses},\n",
    "    }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_last.pkl'))\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "# Evaluate on test set\n",
    "print(f\"[{datetime.now()}] Evaluating on test set...\")\n",
    "net.eval()\n",
    "test_running = 0.0\n",
    "n_test = 0\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "az_errors = []\n",
    "el_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "        az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = net(specs)\n",
    "        loc_out = outputs[0]\n",
    "        cls_out = outputs[1]\n",
    "        elev_out = outputs[2]\n",
    "\n",
    "        loss_loc = criterion_loc(loc_out, loc_xy)\n",
    "        \n",
    "        if num_classes > 1:\n",
    "            loss_cls = criterion_cls(cls_out, cls_idx)\n",
    "            # Calculate classification accuracy\n",
    "            _, predicted = torch.max(cls_out, 1)\n",
    "            test_correct += (predicted == cls_idx).sum().item()\n",
    "        else:\n",
    "            target_bce = cls_idx.float().unsqueeze(1)\n",
    "            loss_cls = criterion_cls(cls_out, target_bce)\n",
    "            # Calculate classification accuracy for binary case\n",
    "            predicted = (cls_out > 0.5).float().squeeze(1)\n",
    "            test_correct += (predicted == cls_idx.float()).sum().item()\n",
    "        \n",
    "        test_total += cls_idx.size(0)\n",
    "        \n",
    "        loss_elev = criterion_elev(elev_out.squeeze(1), az_el_deg[:, 1])\n",
    "\n",
    "        # Calculate azimuth error (assuming loc_out represents azimuth in some form)\n",
    "        # Convert xy coordinates back to azimuth for error calculation\n",
    "        pred_az = torch.atan2(loc_out[:, 1], loc_out[:, 0]) * 180 / torch.pi\n",
    "        true_az = az_el_deg[:, 0]\n",
    "        az_error = torch.abs(pred_az - true_az)\n",
    "        # Handle angle wrapping (e.g., 359째 vs 1째)\n",
    "        az_error = torch.min(az_error, 360 - az_error)\n",
    "        az_errors.extend(az_error.cpu().numpy())\n",
    "        \n",
    "        # Calculate elevation error\n",
    "        pred_el = elev_out.squeeze(1)\n",
    "        true_el = az_el_deg[:, 1]\n",
    "        el_error = torch.abs(pred_el - true_el)\n",
    "        el_errors.extend(el_error.cpu().numpy())\n",
    "\n",
    "        loss = loss_loc + CLS_WEIGHT * loss_cls + ELEV_WEIGHT * loss_elev\n",
    "        bsz = specs.size(0)\n",
    "        test_running += loss.item() * bsz\n",
    "        n_test += bsz\n",
    "\n",
    "avg_test = test_running / max(1, n_test)\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "print(f\"Best validation loss: {best_val:.4f}\")\n",
    "print(f\"Test loss: {avg_test:.4f}\")\n",
    "print(f\"Test accuracy: {test_correct / test_total:.4f}\")\n",
    "print(f\"Average azimuth error: {np.mean(az_errors):.2f}째\")\n",
    "print(f\"Average elevation error: {np.mean(el_errors):.2f}째\")\n",
    "print(f\"Models saved in: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9abe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (Log Scale)')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
