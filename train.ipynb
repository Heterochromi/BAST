{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b917777",
   "metadata": {},
   "source": [
    "# BAST Multitask Training Notebook\n",
    "\n",
    "This notebook recreates the training loop from `train_multitask.py` with all configuration set directly here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from network.BAST import BAST_Variant, AngularLossWithCartesianCoordinate, MixWithCartesianCoordinate , MSELossWithPolarCoordinate\n",
    "from data_loading import SpectrogramDataset\n",
    "import argparse  # Not used but keeping for compatibility\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Set all parameters directly here\n",
    "\n",
    "# Dataset configuration\n",
    "CSV_PATH = 'tensor_metadata.csv'  # Replace with your CSV file path\n",
    "\n",
    "# Model architecture parameters\n",
    "SPECTROGRAM_SIZE = [64, 18]  # [frequency_bins, time_frames] - cropped to 100ms\n",
    "PATCH_SIZE = 16\n",
    "PATCH_OVERLAP = 10\n",
    "NUM_OUTPUT = 3  # Output dimension for localization: [x, y, elevation_deg]\n",
    "EMBEDDING_DIM = 1024\n",
    "TRANSFORMER_DEPTH = 3\n",
    "TRANSFORMER_HEADS = 16\n",
    "TRANSFORMER_MLP_DIM = 1024\n",
    "TRANSFORMER_DIM_HEAD = 64\n",
    "INPUT_CHANNEL = 1  # Single channel per ear\n",
    "DROPOUT = 0.2\n",
    "EMB_DROPOUT = 0.2\n",
    "TRANSFORMER_POOL = 'conv'\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 1500\n",
    "LEARNING_RATE = 0.0001\n",
    "TEST_SPLIT = 0.1  # Test split ratio (10% of total dataset)\n",
    "VAL_SPLIT = 0.2   # Validation split ratio (20% of remaining 90% after test split)\n",
    "SEED = 42\n",
    "\n",
    "# Loss weights\n",
    "LOC_WEIGHT = 1.0      # Localization (azimuth x,y) loss\n",
    "ELEV_WEIGHT = 0.1     # Elevation loss\n",
    "CLS_WEIGHT = 1.0      # Classification loss weight\n",
    "OBJ_WEIGHT = 1.0      # Objectness loss weight\n",
    "\n",
    "# Model configuration\n",
    "BACKBONE = 'vanilla'  # Transformer variant: 'vanilla'\n",
    "BINAURAL_INTEGRATION = 'SUB'  # 'SUB', 'ADD', 'CONCAT'\n",
    "SHARE_WEIGHTS = False  # Share weights between left/right branches\n",
    "MAX_SOURCES = 4        # number of detection slots\n",
    "LOSS_TYPE = 'MIX'      # Localization loss: 'MSE', 'AD', 'MIX'\n",
    "\n",
    "# GPU configuration\n",
    "GPU_LIST = [0] if torch.cuda.is_available() else []  # Use GPU 0 if available\n",
    "\n",
    "# Directory configuration\n",
    "MODEL_SAVE_DIR = './output/models/'\n",
    "MODEL_NAME = 'BAST'\n",
    "\n",
    "# DataLoader configuration\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get localization criterion\n",
    "def get_localization_criterion(name: str):\n",
    "    if name == 'MSE':\n",
    "        return nn.MSELoss()\n",
    "    if name == 'AD':\n",
    "        return AngularLossWithCartesianCoordinate()\n",
    "    if name == 'MIX':\n",
    "        return MixWithCartesianCoordinate()\n",
    "    if name == \"MSE_POLAR\":\n",
    "        return MSELossWithPolarCoordinate()\n",
    "    raise ValueError('Unknown localization loss')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "print(f\"[{datetime.now()}] Loading dataset from {CSV_PATH} ...\")\n",
    "dataset = SpectrogramDataset(CSV_PATH)\n",
    "num_classes = len(dataset.class_to_index)\n",
    "print(f\"[{datetime.now()}] Samples: {len(dataset)} | Classes: {num_classes}\")\n",
    "\n",
    "# Create train/test/validation split\n",
    "test_size = int(len(dataset) * TEST_SPLIT)\n",
    "remaining_size = len(dataset) - test_size\n",
    "\n",
    "# First split off test set\n",
    "remaining_ds, test_ds = random_split(dataset, [remaining_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Then split remaining into train and validation\n",
    "val_size = int(remaining_size * VAL_SPLIT)\n",
    "train_size = remaining_size - val_size\n",
    "train_ds, val_ds = random_split(remaining_ds, [train_size, val_size], generator=torch.Generator().manual_seed(SEED+1))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train set: {len(train_ds)} samples\")\n",
    "print(f\"Validation set: {len(val_ds)} samples\")\n",
    "print(f\"Test set: {len(test_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "print(f\"[{datetime.now()}] Building model ...\")\n",
    "\n",
    "net = BAST_Variant(\n",
    "    image_size=SPECTROGRAM_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    patch_overlap=PATCH_OVERLAP,\n",
    "    num_coordinates_output=NUM_OUTPUT,\n",
    "    dim=EMBEDDING_DIM,\n",
    "    depth=TRANSFORMER_DEPTH,\n",
    "    heads=TRANSFORMER_HEADS,\n",
    "    mlp_dim=TRANSFORMER_MLP_DIM,\n",
    "    pool=TRANSFORMER_POOL,\n",
    "    channels=INPUT_CHANNEL,\n",
    "    dim_head=TRANSFORMER_DIM_HEAD,\n",
    "    dropout=DROPOUT,\n",
    "    emb_dropout=EMB_DROPOUT,\n",
    "    binaural_integration=BINAURAL_INTEGRATION,\n",
    "    share_params=SHARE_WEIGHTS,\n",
    "    transformer_variant=BACKBONE,\n",
    "    max_sources=MAX_SOURCES,\n",
    "    classify_sound=True,\n",
    "    num_classes_cls=num_classes,\n",
    ")\n",
    "\n",
    "# Setup device and move model to device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "if use_cuda and GPU_LIST:\n",
    "    net = nn.DataParallel(net, device_ids=GPU_LIST).to(device)\n",
    "else:\n",
    "    net = net.to(device)\n",
    "\n",
    "print(f\"Model built successfully. Using device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in net.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd512e7d",
   "metadata": {},
   "source": [
    "We now use a detection-style head that outputs per-source slots: (loc_out [B,K,2], obj_logit [B,K], cls_logit [B,K,C]). Losses are computed after matching GT sources to slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and loss functions\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=0.0)\n",
    "criterion_loc = get_localization_criterion(LOSS_TYPE)\n",
    "criterion_elev = nn.MSELoss(reduction='none')          # per-slot elevation MSE (degrees)\n",
    "criterion_obj = nn.BCEWithLogitsLoss(reduction='none')  # per-slot objectness\n",
    "criterion_cls = nn.BCEWithLogitsLoss(reduction='none')  # multi-label per class per slot\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = f\"{MODEL_NAME}_{BINAURAL_INTEGRATION}_{LOSS_TYPE}_DET_{'SP' if SHARE_WEIGHTS else 'NSP'}_{BACKBONE}\"\n",
    "\n",
    "print(f\"Model will be saved as: {model_save_name}\")\n",
    "print(f\"Training for {EPOCHS} epochs with batch size {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Loss weights - Loc: {LOC_WEIGHT}, Elev: {ELEV_WEIGHT}, Cls: {CLS_WEIGHT}, Obj: {OBJ_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for greedy matching (per sample)\n",
    "def greedy_match(pred_xy, gt_xy):\n",
    "    # pred_xy: [K, 2], gt_xy: [N, 2]\n",
    "    K = pred_xy.size(0)\n",
    "    N = gt_xy.size(0)\n",
    "    if N == 0:\n",
    "        return [], torch.empty((0,), dtype=torch.long, device=pred_xy.device)\n",
    "    # pairwise L2 distance\n",
    "    d = torch.cdist(pred_xy, gt_xy, p=2)  # [K, N]\n",
    "    matched_pred_idx = []\n",
    "    matched_gt_idx = []\n",
    "    d_clone = d.clone()\n",
    "    while len(matched_pred_idx) < min(K, N):\n",
    "        # find min remaining\n",
    "        idx = torch.argmin(d_clone)\n",
    "        pi = (idx // N).item()\n",
    "        gi = (idx % N).item()\n",
    "        matched_pred_idx.append(pi)\n",
    "        matched_gt_idx.append(gi)\n",
    "        d_clone[pi, :] = float('inf')\n",
    "        d_clone[:, gi] = float('inf')\n",
    "    return torch.tensor(matched_pred_idx, device=pred_xy.device), torch.tensor(matched_gt_idx, device=pred_xy.device)\n",
    "\n",
    "# Training loop\n",
    "print(f\"[{datetime.now()}] Start training ...\")\n",
    "\n",
    "best_val = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    net.train()\n",
    "    running = 0.0\n",
    "    n_train = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_xy = loc_xy.to(device, non_blocking=True)          # [B, 2]\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)  # [B]\n",
    "\n",
    "        # Forward\n",
    "        loc_out, obj_logit, cls_logit = net(specs)\n",
    "        # Shapes: loc_out [B,K,2], obj_logit [B,K], cls_logit [B,K,C]\n",
    "\n",
    "        B = specs.size(0)\n",
    "        K = obj_logit.size(1)\n",
    "        C = cls_logit.size(2)\n",
    "\n",
    "        # Build targets per sample (single source in CSV; extend to multi by stacking later)\n",
    "        total_loss = torch.tensor(0., device=device)\n",
    "        for b in range(B):\n",
    "            pred_xy_b = loc_out[b][..., :2]       # [K,2] -> azimuth as unit vector\n",
    "            pred_el_b = loc_out[b][..., 2]        # [K]   -> elevation in degrees\n",
    "            obj_b = obj_logit[b]                  # [K]\n",
    "            cls_b = cls_logit[b]                  # [K,C]\n",
    "\n",
    "            # For now, 1 GT source per sample from CSV\n",
    "            gt_xy_b = loc_xy[b].unsqueeze(0)      # [1,2] (unit vector from azimuth)\n",
    "            gt_el_b = az_el_deg[b, 1].unsqueeze(0)  # [1] elevation in degrees\n",
    "            gt_cls_multi_hot = torch.zeros(C, device=device)\n",
    "            gt_cls_multi_hot[cls_idx[b]] = 1.0    # [C]\n",
    "\n",
    "            # Greedy matching on azimuth vectors\n",
    "            pred_idx, gt_idx = greedy_match(pred_xy_b, gt_xy_b)  # sizes: [min(K,1)]\n",
    "\n",
    "            # Objectness targets: matched slots -> 1, others -> 0\n",
    "            obj_target_b = torch.zeros_like(obj_b)\n",
    "            obj_target_b[pred_idx] = 1.0\n",
    "            loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "\n",
    "            # Localization + elevation + class on matched slots only\n",
    "            if pred_idx.numel() > 0:\n",
    "                matched_pred_xy = pred_xy_b[pred_idx]        # [M,2]\n",
    "                matched_gt_xy = gt_xy_b[gt_idx]              # [M,2]\n",
    "                loss_loc_b = criterion_loc(matched_pred_xy, matched_gt_xy)\n",
    "\n",
    "                matched_pred_el = pred_el_b[pred_idx]        # [M]\n",
    "                matched_gt_el = gt_el_b[gt_idx]              # [M]\n",
    "                loss_el_b = criterion_elev(matched_pred_el, matched_gt_el).mean()\n",
    "\n",
    "                matched_cls = cls_b[pred_idx]                # [M,C]\n",
    "                gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "            else:\n",
    "                loss_loc_b = torch.tensor(0., device=device)\n",
    "                loss_el_b = torch.tensor(0., device=device)\n",
    "                loss_cls_b = torch.tensor(0., device=device)\n",
    "\n",
    "            total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + ELEV_WEIGHT * loss_el_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "\n",
    "        loss = total_loss / max(1, B)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bsz = specs.size(0)\n",
    "        running += loss.item() * bsz\n",
    "        n_train += bsz\n",
    "\n",
    "    avg_tr = running / max(1, n_train)\n",
    "    train_losses.append(avg_tr)\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()\n",
    "    running_val = 0.0\n",
    "    n_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "            specs = specs.to(device, non_blocking=True)\n",
    "            loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "            cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "            az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "            loc_out, obj_logit, cls_logit = net(specs)\n",
    "            B = specs.size(0)\n",
    "            total_loss = torch.tensor(0., device=device)\n",
    "            for b in range(B):\n",
    "                pred_xy_b = loc_out[b][..., :2]\n",
    "                pred_el_b = loc_out[b][..., 2]\n",
    "                obj_b = obj_logit[b]\n",
    "                cls_b = cls_logit[b]\n",
    "                gt_xy_b = loc_xy[b].unsqueeze(0)\n",
    "                gt_el_b = az_el_deg[b, 1].unsqueeze(0)\n",
    "                gt_cls_multi_hot = torch.zeros(cls_b.size(1), device=device)\n",
    "                gt_cls_multi_hot[cls_idx[b]] = 1.0\n",
    "                pred_idx, gt_idx = greedy_match(pred_xy_b, gt_xy_b)\n",
    "                obj_target_b = torch.zeros_like(obj_b); obj_target_b[pred_idx] = 1.0\n",
    "                loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "                if pred_idx.numel() > 0:\n",
    "                    matched_pred_xy = pred_xy_b[pred_idx]\n",
    "                    matched_gt_xy = gt_xy_b[gt_idx]\n",
    "                    loss_loc_b = criterion_loc(matched_pred_xy, matched_gt_xy)\n",
    "                    matched_pred_el = pred_el_b[pred_idx]\n",
    "                    matched_gt_el = gt_el_b[gt_idx]\n",
    "                    loss_el_b = criterion_elev(matched_pred_el, matched_gt_el).mean()\n",
    "                    matched_cls = cls_b[pred_idx]\n",
    "                    gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                    loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "                else:\n",
    "                    loss_loc_b = torch.tensor(0., device=device)\n",
    "                    loss_el_b = torch.tensor(0., device=device)\n",
    "                    loss_cls_b = torch.tensor(0., device=device)\n",
    "                total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + ELEV_WEIGHT * loss_el_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "            loss = total_loss / max(1, B)\n",
    "            bsz = specs.size(0)\n",
    "            running_val += loss.item() * bsz\n",
    "            n_val += bsz\n",
    "\n",
    "    avg_val = running_val / max(1, n_val)\n",
    "    val_losses.append(avg_val)\n",
    "\n",
    "    print(f\"[{datetime.now()}] Epoch {epoch+1:03d}/{EPOCHS} | train {avg_tr:.4f} | val {avg_val:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val < best_val:\n",
    "        best_val = avg_val\n",
    "        state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': state,\n",
    "            'best_loss': best_val,\n",
    "            'log': {'training': train_losses, 'validation': val_losses},\n",
    "            'conf': {\n",
    "                'image_size': SPECTROGRAM_SIZE,\n",
    "                'patch_size': PATCH_SIZE,\n",
    "                'patch_overlap': PATCH_OVERLAP,\n",
    "                'num_coordinates_output': NUM_OUTPUT,\n",
    "                'max_sources': MAX_SOURCES,\n",
    "            }\n",
    "        }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_best.pkl'))\n",
    "        print(f\"  -> Saved best model with validation loss: {best_val:.4f}\")\n",
    "\n",
    "    # Save last model\n",
    "    state = net.module.state_dict() if isinstance(net, nn.DataParallel) else net.state_dict()\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state,\n",
    "        'best_loss': best_val,\n",
    "        'log': {'training': train_losses, 'validation': val_losses},\n",
    "    }, os.path.join(MODEL_SAVE_DIR, model_save_name + '_last.pkl'))\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "# Evaluate on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb215086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_ckpt_path = os.path.join(MODEL_SAVE_DIR, model_save_name + '_best.pkl')\n",
    "ckpt = torch.load(best_ckpt_path, map_location=device)\n",
    "state = ckpt['state_dict']\n",
    "if isinstance(net, nn.DataParallel):\n",
    "    net.module.load_state_dict(state)\n",
    "else:\n",
    "    net.load_state_dict(state)\n",
    "print(f\"Loaded best checkpoint from: {best_ckpt_path}\")\n",
    "\n",
    "print(f\"[{datetime.now()}] Evaluating on test set...\")\n",
    "net.eval()\n",
    "test_running = 0.0\n",
    "n_test = 0\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "az_errors = []\n",
    "el_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        specs, loc_xy, cls_idx, az_el_deg = batch\n",
    "        specs = specs.to(device, non_blocking=True)\n",
    "        loc_xy = loc_xy.to(device, non_blocking=True)\n",
    "        cls_idx = cls_idx.to(device, non_blocking=True).squeeze(1)\n",
    "        az_el_deg = az_el_deg.to(device, non_blocking=True)\n",
    "\n",
    "        loc_out, obj_logit, cls_logit = net(specs)\n",
    "        B = specs.size(0)\n",
    "\n",
    "        # Compute detection loss as in validation (optional during eval)\n",
    "        total_loss = torch.tensor(0., device=device)\n",
    "        for b in range(B):\n",
    "            pred_xy_b = loc_out[b]\n",
    "            obj_b = obj_logit[b]\n",
    "            cls_b = cls_logit[b]\n",
    "            gt_xy_b = loc_xy[b].unsqueeze(0)\n",
    "            gt_cls_multi_hot = torch.zeros(cls_b.size(1), device=device)\n",
    "            gt_cls_multi_hot[cls_idx[b]] = 1.0\n",
    "            pred_idx, gt_idx = greedy_match(pred_xy_b, gt_xy_b)\n",
    "            obj_target_b = torch.zeros_like(obj_b); obj_target_b[pred_idx] = 1.0\n",
    "            loss_obj_b = criterion_obj(obj_b, obj_target_b).mean()\n",
    "            if pred_idx.numel() > 0:\n",
    "                matched_pred_xy = pred_xy_b[pred_idx]\n",
    "                matched_gt_xy = gt_xy_b[gt_idx]\n",
    "                loss_loc_b = criterion_loc(matched_pred_xy, matched_gt_xy)\n",
    "                matched_cls = cls_b[pred_idx]\n",
    "                gt_cls_rep = gt_cls_multi_hot.unsqueeze(0).expand(matched_cls.size(0), -1)\n",
    "                loss_cls_b = criterion_cls(matched_cls, gt_cls_rep).mean()\n",
    "            else:\n",
    "                loss_loc_b = torch.tensor(0., device=device)\n",
    "                loss_cls_b = torch.tensor(0., device=device)\n",
    "            total_loss = total_loss + (LOC_WEIGHT * loss_loc_b + CLS_WEIGHT * loss_cls_b + OBJ_WEIGHT * loss_obj_b)\n",
    "        loss = total_loss / max(1, B)\n",
    "\n",
    "        # Metrics: select best slot by objectness\n",
    "        obj_prob = torch.sigmoid(obj_logit)  # [B,K]\n",
    "        best_slot = torch.argmax(obj_prob, dim=1)  # [B]\n",
    "        batch_idx = torch.arange(B, device=device)\n",
    "\n",
    "        pred_loc = loc_out[batch_idx, best_slot]           # [B, num_coordinates_output]\n",
    "        pred_cls_logits = cls_logit[batch_idx, best_slot]  # [B, C]\n",
    "        pred_cls = torch.argmax(pred_cls_logits, dim=1)\n",
    "\n",
    "        test_correct += (pred_cls == cls_idx).sum().item()\n",
    "        test_total += B\n",
    "\n",
    "        # Azimuth error from unit vector [x,y]\n",
    "        pred_theta = torch.atan2(pred_loc[:, 1], pred_loc[:, 0])\n",
    "        pred_az_deg = pred_theta * 180.0 / torch.pi\n",
    "        true_az_deg = az_el_deg[:, 0]\n",
    "        az_err = torch.abs(pred_az_deg - true_az_deg)\n",
    "        az_err = torch.min(az_err, 360 - az_err)\n",
    "        az_errors.extend(az_err.detach().cpu().numpy())\n",
    "\n",
    "        # Elevation error (3rd component is elevation in degrees)\n",
    "        if pred_loc.size(1) >= 3:\n",
    "            pred_el_deg = pred_loc[:, 2]\n",
    "            el_err = torch.abs(pred_el_deg - az_el_deg[:, 1])\n",
    "            el_errors.extend(el_err.detach().cpu().numpy())\n",
    "\n",
    "        bsz = specs.size(0)\n",
    "        test_running += loss.item() * bsz\n",
    "        n_test += bsz\n",
    "\n",
    "avg_test = test_running / max(1, n_test)\n",
    "cls_acc = test_correct / max(1, test_total)\n",
    "mean_az_err = float(np.mean(az_errors)) if len(az_errors) else float('nan')\n",
    "mean_el_err = float(np.mean(el_errors)) if len(el_errors) else float('nan')\n",
    "\n",
    "print(f\"[{datetime.now()}] Training completed!\")\n",
    "print(f\"Best validation loss: {best_val:.4f}\")\n",
    "print(f\"Test loss: {avg_test:.4f}\")\n",
    "print(f\"Classification accuracy: {cls_acc:.4f}\")\n",
    "print(f\"Average azimuth error: {mean_az_err:.2f}°\")\n",
    "if len(el_errors):\n",
    "    print(f\"Average elevation error: {mean_el_err:.2f}°\")\n",
    "else:\n",
    "    print(\"Average elevation error: n/a (model does not output elevation)\")\n",
    "print(f\"Models saved in: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9abe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (Log Scale)')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d1e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
